Using TensorFlow backend.
X: (11487, 80, 160, 3) -> Y: (11487, 80, 160, 1)
2017-12-17 16:41:16.150765: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 16:41:16.150791: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 16:41:16.150796: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 16:41:16.150818: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, butthese are available on your machine and could speed up CPU computations.
2017-12-17 16:41:16.150822: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 16:41:16.259110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-12-17 16:41:16.259537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX 1050 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.62
pciBusID 0000:01:00.0
Total memory: 3.94GiB
Free memory: 3.51GiB
2017-12-17 16:41:16.259558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-12-17 16:41:16.259585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-12-17 16:41:16.259613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0)
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_1 (InputLayer)             (None, 80, 160, 3)    0
____________________________________________________________________________________________________
batch_normalization_1 (BatchNorm (None, 80, 160, 3)    12          input_1[0][0]
____________________________________________________________________________________________________
Conv0 (Conv2D)                   (None, 78, 158, 16)   448         batch_normalization_1[0][0]
____________________________________________________________________________________________________
Conv1C (Conv2D)                  (None, 76, 156, 32)   4640        Conv0[0][0]
____________________________________________________________________________________________________
Pooling1C (MaxPooling2D)         (None, 38, 78, 32)    0           Conv1C[0][0]
____________________________________________________________________________________________________
Conv2C (Conv2D)                  (None, 36, 76, 64)    18496       Pooling1C[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 36, 76, 64)    0           Conv2C[0][0]
____________________________________________________________________________________________________
Pooling2C (MaxPooling2D)         (None, 18, 38, 64)    0           dropout_3[0][0]
____________________________________________________________________________________________________
Conv3C (Conv2D)                  (None, 16, 36, 128)   73856       Pooling2C[0][0]
____________________________________________________________________________________________________
Conv1B (Conv2D)                  (None, 76, 156, 32)   4640        Conv0[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 16, 36, 128)   0           Conv3C[0][0]
____________________________________________________________________________________________________
Pooling1B (MaxPooling2D)         (None, 38, 78, 32)    0           Conv1B[0][0]
____________________________________________________________________________________________________
Pooling3C (MaxPooling2D)         (None, 8, 18, 128)    0           dropout_4[0][0]
____________________________________________________________________________________________________
Conv2B (Conv2D)                  (None, 36, 76, 64)    18496       Pooling1B[0][0]
____________________________________________________________________________________________________
UpSampling1C (UpSampling2D)      (None, 16, 36, 128)   0           Pooling3C[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 36, 76, 64)    0           Conv2B[0][0]
____________________________________________________________________________________________________
Deconv1C (Conv2DTranspose)       (None, 18, 38, 128)   147584      UpSampling1C[0][0]
____________________________________________________________________________________________________
Conv1A (Conv2D)                  (None, 76, 156, 32)   4640        Conv0[0][0]
____________________________________________________________________________________________________
Pooling2B (MaxPooling2D)         (None, 18, 38, 64)    0           dropout_2[0][0]
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 18, 38, 128)   0           Deconv1C[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 76, 156, 32)   0           Conv1A[0][0]
____________________________________________________________________________________________________
UpSampling1B (UpSampling2D)      (None, 36, 76, 64)    0           Pooling2B[0][0]
____________________________________________________________________________________________________
UpSampling2C (UpSampling2D)      (None, 36, 76, 128)   0           dropout_5[0][0]
____________________________________________________________________________________________________
Pooling1A (MaxPooling2D)         (None, 38, 78, 32)    0           dropout_1[0][0]
____________________________________________________________________________________________________
Deconv1B (Conv2DTranspose)       (None, 38, 78, 64)    36928       UpSampling1B[0][0]
____________________________________________________________________________________________________
Deconv2C (Conv2DTranspose)       (None, 38, 78, 64)    73792       UpSampling2C[0][0]
____________________________________________________________________________________________________
UpSampling1A (UpSampling2D)      (None, 76, 156, 32)   0           Pooling1A[0][0]
____________________________________________________________________________________________________
dropout_7 (Dropout)              (None, 38, 78, 64)    0           Deconv1B[0][0]
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 38, 78, 64)    0           Deconv2C[0][0]
____________________________________________________________________________________________________
Deconv1A (Conv2DTranspose)       (None, 78, 158, 32)   9248        UpSampling1A[0][0]
____________________________________________________________________________________________________
UpSampling2B (UpSampling2D)      (None, 76, 156, 64)   0           dropout_7[0][0]
____________________________________________________________________________________________________
UpSampling3C (UpSampling2D)      (None, 76, 156, 64)   0           dropout_6[0][0]
____________________________________________________________________________________________________
dropout_8 (Dropout)              (None, 78, 158, 32)   0           Deconv1A[0][0]
____________________________________________________________________________________________________
Deconv2B (Conv2DTranspose)       (None, 78, 158, 32)   18464       UpSampling2B[0][0]
____________________________________________________________________________________________________
Deconv3C (Conv2DTranspose)       (None, 78, 158, 32)   18464       UpSampling3C[0][0]
____________________________________________________________________________________________________
concatenate_1 (Concatenate)      (None, 78, 158, 96)   0           dropout_8[0][0]
                                                                   Deconv2B[0][0]
                                                                   Deconv3C[0][0]
____________________________________________________________________________________________________
Deconv0 (Conv2DTranspose)        (None, 80, 160, 1)    865         concatenate_1[0][0]
====================================================================================================
Total params: 430,573
Trainable params: 430,567
Non-trainable params: 6
____________________________________________________________________________________________________
Epoch 1/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9481Epoch 00000: saving model to weights_b_dropout/weights.00-0.0173-0.9481.hdf5
11487/11487 [==============================] - 170s - loss: 0.0173 - acc: 0.9481
Epoch 2/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9596Epoch 00001: saving model to weights_b_dropout/weights.01-0.0066-0.9596.hdf5
11487/11487 [==============================] - 163s - loss: 0.0066 - acc: 0.9596
Epoch 3/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9603Epoch 00002: saving model to weights_b_dropout/weights.02-0.0056-0.9603.hdf5
11487/11487 [==============================] - 162s - loss: 0.0056 - acc: 0.9603
Epoch 4/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9608Epoch 00003: saving model to weights_b_dropout/weights.03-0.0051-0.9608.hdf5
11487/11487 [==============================] - 163s - loss: 0.0051 - acc: 0.9608
Epoch 5/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9612Epoch 00004: saving model to weights_b_dropout/weights.04-0.0047-0.9612.hdf5
11487/11487 [==============================] - 167s - loss: 0.0047 - acc: 0.9612
Epoch 6/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9614Epoch 00005: saving model to weights_b_dropout/weights.05-0.0044-0.9614.hdf5
11487/11487 [==============================] - 166s - loss: 0.0044 - acc: 0.9614
Epoch 7/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9615Epoch 00006: saving model to weights_b_dropout/weights.06-0.0042-0.9615.hdf5
11487/11487 [==============================] - 164s - loss: 0.0042 - acc: 0.9615
Epoch 8/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9617Epoch 00007: saving model to weights_b_dropout/weights.07-0.0040-0.9617.hdf5
11487/11487 [==============================] - 163s - loss: 0.0040 - acc: 0.9617
Epoch 9/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9618Epoch 00008: saving model to weights_b_dropout/weights.08-0.0038-0.9618.hdf5
11487/11487 [==============================] - 165s - loss: 0.0038 - acc: 0.9618
Epoch 10/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9619Epoch 00009: saving model to weights_b_dropout/weights.09-0.0037-0.9619.hdf5
11487/11487 [==============================] - 163s - loss: 0.0037 - acc: 0.9619
Epoch 11/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9621Epoch 00010: saving model to weights_b_dropout/weights.10-0.0035-0.9621.hdf5
11487/11487 [==============================] - 164s - loss: 0.0035 - acc: 0.9621
Epoch 12/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9622Epoch 00011: saving model to weights_b_dropout/weights.11-0.0034-0.9622.hdf5
11487/11487 [==============================] - 165s - loss: 0.0034 - acc: 0.9622
Epoch 13/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9622Epoch 00012: saving model to weights_b_dropout/weights.12-0.0033-0.9622.hdf5
11487/11487 [==============================] - 162s - loss: 0.0033 - acc: 0.9622
Epoch 14/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9625Epoch 00013: saving model to weights_b_dropout/weights.13-0.0031-0.9625.hdf5
11487/11487 [==============================] - 162s - loss: 0.0031 - acc: 0.9625
Epoch 15/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9626Epoch 00014: saving model to weights_b_dropout/weights.14-0.0029-0.9626.hdf5
11487/11487 [==============================] - 163s - loss: 0.0029 - acc: 0.9626
Epoch 16/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9626Epoch 00015: saving model to weights_b_dropout/weights.15-0.0030-0.9626.hdf5
11487/11487 [==============================] - 162s - loss: 0.0030 - acc: 0.9626
Epoch 17/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9627Epoch 00016: saving model to weights_b_dropout/weights.16-0.0028-0.9627.hdf5
11487/11487 [==============================] - 162s - loss: 0.0028 - acc: 0.9627
Epoch 18/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9628Epoch 00017: saving model to weights_b_dropout/weights.17-0.0027-0.9628.hdf5
11487/11487 [==============================] - 162s - loss: 0.0027 - acc: 0.9628
Epoch 19/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9628Epoch 00018: saving model to weights_b_dropout/weights.18-0.0026-0.9628.hdf5
11487/11487 [==============================] - 163s - loss: 0.0026 - acc: 0.9628
Epoch 20/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9628Epoch 00019: saving model to weights_b_dropout/weights.19-0.0027-0.9628.hdf5
11487/11487 [==============================] - 162s - loss: 0.0027 - acc: 0.9628
Epoch 21/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9629Epoch 00020: saving model to weights_b_dropout/weights.20-0.0026-0.9629.hdf5
11487/11487 [==============================] - 162s - loss: 0.0026 - acc: 0.9629
Epoch 22/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9630Epoch 00021: saving model to weights_b_dropout/weights.21-0.0024-0.9630.hdf5
11487/11487 [==============================] - 164s - loss: 0.0024 - acc: 0.9630
Epoch 23/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9631Epoch 00022: saving model to weights_b_dropout/weights.22-0.0023-0.9631.hdf5
11487/11487 [==============================] - 162s - loss: 0.0023 - acc: 0.9631
Epoch 24/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9631Epoch 00023: saving model to weights_b_dropout/weights.23-0.0024-0.9631.hdf5
11487/11487 [==============================] - 163s - loss: 0.0024 - acc: 0.9631
Epoch 25/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9631Epoch 00024: saving model to weights_b_dropout/weights.24-0.0023-0.9631.hdf5
11487/11487 [==============================] - 162s - loss: 0.0023 - acc: 0.9631
Epoch 26/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9631Epoch 00025: saving model to weights_b_dropout/weights.25-0.0023-0.9631.hdf5
11487/11487 [==============================] - 162s - loss: 0.0023 - acc: 0.9631
Epoch 27/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9632Epoch 00026: saving model to weights_b_dropout/weights.26-0.0022-0.9632.hdf5
11487/11487 [==============================] - 162s - loss: 0.0022 - acc: 0.9632
Epoch 28/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9631Epoch 00027: saving model to weights_b_dropout/weights.27-0.0023-0.9631.hdf5
11487/11487 [==============================] - 162s - loss: 0.0023 - acc: 0.9631
Epoch 29/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9633Epoch 00028: saving model to weights_b_dropout/weights.28-0.0021-0.9633.hdf5
11487/11487 [==============================] - 164s - loss: 0.0021 - acc: 0.9633
Epoch 30/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9633Epoch 00029: saving model to weights_b_dropout/weights.29-0.0021-0.9633.hdf5
11487/11487 [==============================] - 163s - loss: 0.0021 - acc: 0.9633
Epoch 31/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9632Epoch 00030: saving model to weights_b_dropout/weights.30-0.0021-0.9632.hdf5
11487/11487 [==============================] - 163s - loss: 0.0021 - acc: 0.9632
Epoch 32/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9633Epoch 00031: saving model to weights_b_dropout/weights.31-0.0020-0.9633.hdf5
11487/11487 [==============================] - 163s - loss: 0.0020 - acc: 0.9633
Epoch 33/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9633Epoch 00032: saving model to weights_b_dropout/weights.32-0.0020-0.9633.hdf5
11487/11487 [==============================] - 162s - loss: 0.0020 - acc: 0.9633
Epoch 34/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9634Epoch 00033: saving model to weights_b_dropout/weights.33-0.0020-0.9634.hdf5
11487/11487 [==============================] - 162s - loss: 0.0020 - acc: 0.9634
Epoch 35/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9634Epoch 00034: saving model to weights_b_dropout/weights.34-0.0020-0.9634.hdf5
11487/11487 [==============================] - 162s - loss: 0.0020 - acc: 0.9634
Epoch 36/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9633Epoch 00035: saving model to weights_b_dropout/weights.35-0.0020-0.9633.hdf5
11487/11487 [==============================] - 162s - loss: 0.0020 - acc: 0.9633
Epoch 37/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9634Epoch 00036: saving model to weights_b_dropout/weights.36-0.0019-0.9634.hdf5
11487/11487 [==============================] - 162s - loss: 0.0019 - acc: 0.9634
Epoch 38/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9634Epoch 00037: saving model to weights_b_dropout/weights.37-0.0019-0.9634.hdf5
11487/11487 [==============================] - 161s - loss: 0.0019 - acc: 0.9634
Epoch 39/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00038: saving model to weights_b_dropout/weights.38-0.0018-0.9635.hdf5
11487/11487 [==============================] - 161s - loss: 0.0018 - acc: 0.9635
Epoch 40/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00039: saving model to weights_b_dropout/weights.39-0.0018-0.9635.hdf5
11487/11487 [==============================] - 161s - loss: 0.0018 - acc: 0.9635
Epoch 41/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9634Epoch 00040: saving model to weights_b_dropout/weights.40-0.0019-0.9634.hdf5
11487/11487 [==============================] - 161s - loss: 0.0019 - acc: 0.9634
Epoch 42/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00041: saving model to weights_b_dropout/weights.41-0.0018-0.9635.hdf5
11487/11487 [==============================] - 161s - loss: 0.0018 - acc: 0.9635
Epoch 43/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9635Epoch 00042: saving model to weights_b_dropout/weights.42-0.0017-0.9635.hdf5
11487/11487 [==============================] - 161s - loss: 0.0017 - acc: 0.9635
Epoch 44/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9636Epoch 00043: saving model to weights_b_dropout/weights.43-0.0017-0.9636.hdf5
11487/11487 [==============================] - 161s - loss: 0.0017 - acc: 0.9636
Epoch 45/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00044: saving model to weights_b_dropout/weights.44-0.0018-0.9635.hdf5
11487/11487 [==============================] - 161s - loss: 0.0018 - acc: 0.9635
Epoch 46/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9634Epoch 00045: saving model to weights_b_dropout/weights.45-0.0019-0.9634.hdf5
11487/11487 [==============================] - 161s - loss: 0.0019 - acc: 0.9634
Epoch 47/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9635Epoch 00046: saving model to weights_b_dropout/weights.46-0.0017-0.9635.hdf5
11487/11487 [==============================] - 161s - loss: 0.0017 - acc: 0.9635
Epoch 48/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9636Epoch 00047: saving model to weights_b_dropout/weights.47-0.0017-0.9636.hdf5
11487/11487 [==============================] - 161s - loss: 0.0017 - acc: 0.9636
Epoch 49/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9636Epoch 00048: saving model to weights_b_dropout/weights.48-0.0017-0.9636.hdf5
11487/11487 [==============================] - 161s - loss: 0.0017 - acc: 0.9636
Epoch 50/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9636Epoch 00049: saving model to weights_b_dropout/weights.49-0.0016-0.9636.hdf5
11487/11487 [==============================] - 161s - loss: 0.0016 - acc: 0.9636
Epoch 51/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9636Epoch 00050: saving model to weights_b_dropout/weights.50-0.0016-0.9636.hdf5
11487/11487 [==============================] - 161s - loss: 0.0016 - acc: 0.9636
Epoch 52/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9636Epoch 00051: saving model to weights_b_dropout/weights.51-0.0017-0.9636.hdf5
11487/11487 [==============================] - 161s - loss: 0.0017 - acc: 0.9636
Epoch 53/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9636Epoch 00052: saving model to weights_b_dropout/weights.52-0.0016-0.9636.hdf5
11487/11487 [==============================] - 161s - loss: 0.0016 - acc: 0.9636
Epoch 54/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9636Epoch 00053: saving model to weights_b_dropout/weights.53-0.0016-0.9636.hdf5
11487/11487 [==============================] - 161s - loss: 0.0016 - acc: 0.9636
Epoch 55/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9635Epoch 00054: saving model to weights_b_dropout/weights.54-0.0017-0.9635.hdf5
11487/11487 [==============================] - 161s - loss: 0.0017 - acc: 0.9635
Epoch 56/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9637Epoch 00055: saving model to weights_b_dropout/weights.55-0.0016-0.9637.hdf5
11487/11487 [==============================] - 161s - loss: 0.0016 - acc: 0.9637
Epoch 57/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9637Epoch 00056: saving model to weights_b_dropout/weights.56-0.0015-0.9637.hdf5
11487/11487 [==============================] - 161s - loss: 0.0015 - acc: 0.9637
Epoch 58/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9637Epoch 00057: saving model to weights_b_dropout/weights.57-0.0015-0.9637.hdf5
11487/11487 [==============================] - 161s - loss: 0.0015 - acc: 0.9637
Epoch 59/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9636Epoch 00058: saving model to weights_b_dropout/weights.58-0.0016-0.9636.hdf5
11487/11487 [==============================] - 161s - loss: 0.0016 - acc: 0.9636
Epoch 60/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9637Epoch 00059: saving model to weights_b_dropout/weights.59-0.0015-0.9637.hdf5
11487/11487 [==============================] - 161s - loss: 0.0015 - acc: 0.9637
Epoch 61/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9637Epoch 00060: saving model to weights_b_dropout/weights.60-0.0015-0.9637.hdf5
11487/11487 [==============================] - 161s - loss: 0.0015 - acc: 0.9637
Epoch 62/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9637Epoch 00061: saving model to weights_b_dropout/weights.61-0.0015-0.9637.hdf5
11487/11487 [==============================] - 161s - loss: 0.0015 - acc: 0.9637
Epoch 63/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9635Epoch 00062: saving model to weights_b_dropout/weights.62-0.0017-0.9636.hdf5
11487/11487 [==============================] - 161s - loss: 0.0017 - acc: 0.9636
Epoch 64/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9637Epoch 00063: saving model to weights_b_dropout/weights.63-0.0015-0.9637.hdf5
11487/11487 [==============================] - 161s - loss: 0.0015 - acc: 0.9637
Epoch 65/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9637Epoch 00064: saving model to weights_b_dropout/weights.64-0.0014-0.9637.hdf5
11487/11487 [==============================] - 161s - loss: 0.0014 - acc: 0.9637
Epoch 66/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9637Epoch 00065: saving model to weights_b_dropout/weights.65-0.0015-0.9637.hdf5
11487/11487 [==============================] - 161s - loss: 0.0015 - acc: 0.9637
Epoch 67/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9636Epoch 00066: saving model to weights_b_dropout/weights.66-0.0016-0.9636.hdf5
11487/11487 [==============================] - 161s - loss: 0.0016 - acc: 0.9636
Epoch 68/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9637Epoch 00067: saving model to weights_b_dropout/weights.67-0.0014-0.9637.hdf5
11487/11487 [==============================] - 161s - loss: 0.0014 - acc: 0.9637
Epoch 69/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9637Epoch 00068: saving model to weights_b_dropout/weights.68-0.0014-0.9637.hdf5
11487/11487 [==============================] - 161s - loss: 0.0014 - acc: 0.9637
Epoch 70/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9637Epoch 00069: saving model to weights_b_dropout/weights.69-0.0014-0.9637.hdf5
11487/11487 [==============================] - 161s - loss: 0.0014 - acc: 0.9637
Epoch 71/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9637Epoch 00070: saving model to weights_b_dropout/weights.70-0.0014-0.9637.hdf5
11487/11487 [==============================] - 161s - loss: 0.0014 - acc: 0.9637
Epoch 72/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9637Epoch 00071: saving model to weights_b_dropout/weights.71-0.0014-0.9637.hdf5
11487/11487 [==============================] - 163s - loss: 0.0014 - acc: 0.9637
Epoch 73/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9638Epoch 00072: saving model to weights_b_dropout/weights.72-0.0014-0.9638.hdf5
11487/11487 [==============================] - 162s - loss: 0.0014 - acc: 0.9638
Epoch 74/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9637Epoch 00073: saving model to weights_b_dropout/weights.73-0.0014-0.9637.hdf5
11487/11487 [==============================] - 162s - loss: 0.0014 - acc: 0.9637
Epoch 75/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9638Epoch 00074: saving model to weights_b_dropout/weights.74-0.0014-0.9638.hdf5
11487/11487 [==============================] - 162s - loss: 0.0014 - acc: 0.9638
Epoch 76/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9638Epoch 00075: saving model to weights_b_dropout/weights.75-0.0014-0.9638.hdf5
11487/11487 [==============================] - 163s - loss: 0.0014 - acc: 0.9638
Epoch 77/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9638Epoch 00076: saving model to weights_b_dropout/weights.76-0.0014-0.9638.hdf5
11487/11487 [==============================] - 163s - loss: 0.0014 - acc: 0.9638
Epoch 78/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9638Epoch 00077: saving model to weights_b_dropout/weights.77-0.0014-0.9638.hdf5
11487/11487 [==============================] - 163s - loss: 0.0014 - acc: 0.9638
Epoch 79/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9638Epoch 00078: saving model to weights_b_dropout/weights.78-0.0014-0.9638.hdf5
11487/11487 [==============================] - 163s - loss: 0.0014 - acc: 0.9638
Epoch 80/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00079: saving model to weights_b_dropout/weights.79-0.0013-0.9638.hdf5
11487/11487 [==============================] - 163s - loss: 0.0013 - acc: 0.9638
Epoch 81/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00080: saving model to weights_b_dropout/weights.80-0.0013-0.9638.hdf5
11487/11487 [==============================] - 163s - loss: 0.0013 - acc: 0.9638
Epoch 82/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00081: saving model to weights_b_dropout/weights.81-0.0013-0.9638.hdf5
11487/11487 [==============================] - 163s - loss: 0.0013 - acc: 0.9638
Epoch 83/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00082: saving model to weights_b_dropout/weights.82-0.0013-0.9638.hdf5
11487/11487 [==============================] - 164s - loss: 0.0013 - acc: 0.9638
Epoch 84/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9638Epoch 00083: saving model to weights_b_dropout/weights.83-0.0014-0.9638.hdf5
11487/11487 [==============================] - 164s - loss: 0.0014 - acc: 0.9638
Epoch 85/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00084: saving model to weights_b_dropout/weights.84-0.0013-0.9638.hdf5
11487/11487 [==============================] - 165s - loss: 0.0013 - acc: 0.9638
Epoch 86/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00085: saving model to weights_b_dropout/weights.85-0.0013-0.9638.hdf5
11487/11487 [==============================] - 163s - loss: 0.0013 - acc: 0.9638
Epoch 87/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00086: saving model to weights_b_dropout/weights.86-0.0013-0.9638.hdf5
11487/11487 [==============================] - 165s - loss: 0.0013 - acc: 0.9638
Epoch 88/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00087: saving model to weights_b_dropout/weights.87-0.0013-0.9638.hdf5
11487/11487 [==============================] - 164s - loss: 0.0013 - acc: 0.9638
Epoch 89/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00088: saving model to weights_b_dropout/weights.88-0.0013-0.9638.hdf5
11487/11487 [==============================] - 166s - loss: 0.0013 - acc: 0.9638
Epoch 90/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00089: saving model to weights_b_dropout/weights.89-0.0013-0.9638.hdf5
11487/11487 [==============================] - 162s - loss: 0.0013 - acc: 0.9638
Epoch 91/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00090: saving model to weights_b_dropout/weights.90-0.0013-0.9638.hdf5
11487/11487 [==============================] - 163s - loss: 0.0013 - acc: 0.9638
Epoch 92/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00091: saving model to weights_b_dropout/weights.91-0.0013-0.9638.hdf5
11487/11487 [==============================] - 162s - loss: 0.0013 - acc: 0.9638
Epoch 93/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9638Epoch 00092: saving model to weights_b_dropout/weights.92-0.0014-0.9637.hdf5
11487/11487 [==============================] - 162s - loss: 0.0014 - acc: 0.9637
Epoch 94/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00093: saving model to weights_b_dropout/weights.93-0.0013-0.9638.hdf5
11487/11487 [==============================] - 164s - loss: 0.0013 - acc: 0.9638
Epoch 95/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9639Epoch 00094: saving model to weights_b_dropout/weights.94-0.0012-0.9639.hdf5
11487/11487 [==============================] - 163s - loss: 0.0012 - acc: 0.9639
Epoch 96/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9639Epoch 00095: saving model to weights_b_dropout/weights.95-0.0012-0.9639.hdf5
11487/11487 [==============================] - 162s - loss: 0.0012 - acc: 0.9639
Epoch 97/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9638Epoch 00096: saving model to weights_b_dropout/weights.96-0.0012-0.9638.hdf5
11487/11487 [==============================] - 162s - loss: 0.0012 - acc: 0.9638
Epoch 98/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9639Epoch 00097: saving model to weights_b_dropout/weights.97-0.0012-0.9639.hdf5
11487/11487 [==============================] - 162s - loss: 0.0012 - acc: 0.9639
Epoch 99/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9638Epoch 00098: saving model to weights_b_dropout/weights.98-0.0012-0.9638.hdf5
11487/11487 [==============================] - 162s - loss: 0.0012 - acc: 0.9638
Epoch 100/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9639Epoch 00099: saving model to weights_b_dropout/weights.99-0.0012-0.9639.hdf5
11487/11487 [==============================] - 163s - loss: 0.0012 - acc: 0.9639
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_1 (InputLayer)             (None, 80, 160, 3)    0
____________________________________________________________________________________________________
batch_normalization_1 (BatchNorm (None, 80, 160, 3)    12          input_1[0][0]
____________________________________________________________________________________________________
Conv0 (Conv2D)                   (None, 78, 158, 16)   448         batch_normalization_1[0][0]
____________________________________________________________________________________________________
Conv1C (Conv2D)                  (None, 76, 156, 32)   4640        Conv0[0][0]
____________________________________________________________________________________________________
Pooling1C (MaxPooling2D)         (None, 38, 78, 32)    0           Conv1C[0][0]
____________________________________________________________________________________________________
Conv2C (Conv2D)                  (None, 36, 76, 64)    18496       Pooling1C[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 36, 76, 64)    0           Conv2C[0][0]
____________________________________________________________________________________________________
Pooling2C (MaxPooling2D)         (None, 18, 38, 64)    0           dropout_3[0][0]
____________________________________________________________________________________________________
Conv3C (Conv2D)                  (None, 16, 36, 128)   73856       Pooling2C[0][0]
____________________________________________________________________________________________________
Conv1B (Conv2D)                  (None, 76, 156, 32)   4640        Conv0[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 16, 36, 128)   0           Conv3C[0][0]
____________________________________________________________________________________________________
Pooling1B (MaxPooling2D)         (None, 38, 78, 32)    0           Conv1B[0][0]
____________________________________________________________________________________________________
Pooling3C (MaxPooling2D)         (None, 8, 18, 128)    0           dropout_4[0][0]
____________________________________________________________________________________________________
Conv2B (Conv2D)                  (None, 36, 76, 64)    18496       Pooling1B[0][0]
____________________________________________________________________________________________________
UpSampling1C (UpSampling2D)      (None, 16, 36, 128)   0           Pooling3C[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 36, 76, 64)    0           Conv2B[0][0]
____________________________________________________________________________________________________
Deconv1C (Conv2DTranspose)       (None, 18, 38, 128)   147584      UpSampling1C[0][0]
____________________________________________________________________________________________________
Conv1A (Conv2D)                  (None, 76, 156, 32)   4640        Conv0[0][0]
____________________________________________________________________________________________________
Pooling2B (MaxPooling2D)         (None, 18, 38, 64)    0           dropout_2[0][0]
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 18, 38, 128)   0           Deconv1C[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 76, 156, 32)   0           Conv1A[0][0]
____________________________________________________________________________________________________
UpSampling1B (UpSampling2D)      (None, 36, 76, 64)    0           Pooling2B[0][0]
____________________________________________________________________________________________________
UpSampling2C (UpSampling2D)      (None, 36, 76, 128)   0           dropout_5[0][0]
____________________________________________________________________________________________________
Pooling1A (MaxPooling2D)         (None, 38, 78, 32)    0           dropout_1[0][0]
____________________________________________________________________________________________________
Deconv1B (Conv2DTranspose)       (None, 38, 78, 64)    36928       UpSampling1B[0][0]
____________________________________________________________________________________________________
Deconv2C (Conv2DTranspose)       (None, 38, 78, 64)    73792       UpSampling2C[0][0]
____________________________________________________________________________________________________
UpSampling1A (UpSampling2D)      (None, 76, 156, 32)   0           Pooling1A[0][0]
____________________________________________________________________________________________________
dropout_7 (Dropout)              (None, 38, 78, 64)    0           Deconv1B[0][0]
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 38, 78, 64)    0           Deconv2C[0][0]
____________________________________________________________________________________________________
Deconv1A (Conv2DTranspose)       (None, 78, 158, 32)   9248        UpSampling1A[0][0]
____________________________________________________________________________________________________
UpSampling2B (UpSampling2D)      (None, 76, 156, 64)   0           dropout_7[0][0]
____________________________________________________________________________________________________
UpSampling3C (UpSampling2D)      (None, 76, 156, 64)   0           dropout_6[0][0]
____________________________________________________________________________________________________
dropout_8 (Dropout)              (None, 78, 158, 32)   0           Deconv1A[0][0]
____________________________________________________________________________________________________
Deconv2B (Conv2DTranspose)       (None, 78, 158, 32)   18464       UpSampling2B[0][0]
____________________________________________________________________________________________________
Deconv3C (Conv2DTranspose)       (None, 78, 158, 32)   18464       UpSampling3C[0][0]
____________________________________________________________________________________________________
concatenate_1 (Concatenate)      (None, 78, 158, 96)   0           dropout_8[0][0]
                                                                   Deconv2B[0][0]
                                                                   Deconv3C[0][0]
____________________________________________________________________________________________________
Deconv0 (Conv2DTranspose)        (None, 80, 160, 1)    865         concatenate_1[0][0]
====================================================================================================
Total params: 430,573
Trainable params: 430,567
Non-trainable params: 6
____________________________________________________________________________________________________