Using TensorFlow backend.
X: (11487, 80, 160, 3) -> Y: (11487, 80, 160, 1)
2017-12-17 21:34:11.501901: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 21:34:11.501930: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 21:34:11.501953: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 21:34:11.501957: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, butthese are available on your machine and could speed up CPU computations.
2017-12-17 21:34:11.501961: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 21:34:11.637968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-12-17 21:34:11.638310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX 1050 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.62
pciBusID 0000:01:00.0
Total memory: 3.94GiB
Free memory: 3.36GiB
2017-12-17 21:34:11.638347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-12-17 21:34:11.638352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-12-17 21:34:11.638361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0)
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_1 (InputLayer)             (None, 80, 160, 3)    0
____________________________________________________________________________________________________
batch_normalization_1 (BatchNorm (None, 80, 160, 3)    12          input_1[0][0]
____________________________________________________________________________________________________
Conv0 (Conv2D)                   (None, 78, 158, 16)   448         batch_normalization_1[0][0]
____________________________________________________________________________________________________
Conv1C (Conv2D)                  (None, 76, 156, 16)   2320        Conv0[0][0]
____________________________________________________________________________________________________
Conv1F (Conv2D)                  (None, 68, 148, 16)   30992       Conv0[0][0]
____________________________________________________________________________________________________
Pooling1C (MaxPooling2D)         (None, 38, 78, 16)    0           Conv1C[0][0]
____________________________________________________________________________________________________
Pooling1F (MaxPooling2D)         (None, 34, 74, 16)    0           Conv1F[0][0]
____________________________________________________________________________________________________
Conv2C (Conv2D)                  (None, 36, 76, 32)    4640        Pooling1C[0][0]
____________________________________________________________________________________________________
Conv2F (Conv2D)                  (None, 24, 64, 32)    61984       Pooling1F[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 36, 76, 32)    0           Conv2C[0][0]
____________________________________________________________________________________________________
dropout_7 (Dropout)              (None, 24, 64, 32)    0           Conv2F[0][0]
____________________________________________________________________________________________________
Pooling2C (MaxPooling2D)         (None, 18, 38, 32)    0           dropout_3[0][0]
____________________________________________________________________________________________________
Pooling2F (MaxPooling2D)         (None, 12, 32, 32)    0           dropout_7[0][0]
____________________________________________________________________________________________________
Conv3C (Conv2D)                  (None, 16, 36, 64)    18496       Pooling2C[0][0]
____________________________________________________________________________________________________
Conv3F (Conv2D)                  (None, 2, 22, 64)     247872      Pooling2F[0][0]
____________________________________________________________________________________________________
Conv1B (Conv2D)                  (None, 76, 156, 16)   2320        Conv0[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 16, 36, 64)    0           Conv3C[0][0]
____________________________________________________________________________________________________
Conv1E (Conv2D)                  (None, 68, 148, 16)   30992       Conv0[0][0]
____________________________________________________________________________________________________
dropout_8 (Dropout)              (None, 2, 22, 64)     0           Conv3F[0][0]
____________________________________________________________________________________________________
Pooling1B (MaxPooling2D)         (None, 38, 78, 16)    0           Conv1B[0][0]
____________________________________________________________________________________________________
Pooling3C (MaxPooling2D)         (None, 8, 18, 64)     0           dropout_4[0][0]
____________________________________________________________________________________________________
Pooling1E (MaxPooling2D)         (None, 34, 74, 16)    0           Conv1E[0][0]
____________________________________________________________________________________________________
Pooling3F (MaxPooling2D)         (None, 1, 11, 64)     0           dropout_8[0][0]
____________________________________________________________________________________________________
Conv2B (Conv2D)                  (None, 36, 76, 32)    4640        Pooling1B[0][0]
____________________________________________________________________________________________________
UpSampling1C (UpSampling2D)      (None, 16, 36, 64)    0           Pooling3C[0][0]
____________________________________________________________________________________________________
Conv2E (Conv2D)                  (None, 24, 64, 32)    61984       Pooling1E[0][0]
____________________________________________________________________________________________________
UpSampling1F (UpSampling2D)      (None, 2, 22, 64)     0           Pooling3F[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 36, 76, 32)    0           Conv2B[0][0]
____________________________________________________________________________________________________
Deconv1C (Conv2DTranspose)       (None, 18, 38, 64)    36928       UpSampling1C[0][0]
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 24, 64, 32)    0           Conv2E[0][0]
____________________________________________________________________________________________________
Deconv1F (Conv2DTranspose)       (None, 12, 32, 64)    495680      UpSampling1F[0][0]
____________________________________________________________________________________________________
Conv1A (Conv2D)                  (None, 76, 156, 16)   2320        Conv0[0][0]
____________________________________________________________________________________________________
Pooling2B (MaxPooling2D)         (None, 18, 38, 32)    0           dropout_2[0][0]
____________________________________________________________________________________________________
dropout_13 (Dropout)             (None, 18, 38, 64)    0           Deconv1C[0][0]
____________________________________________________________________________________________________
Conv1D (Conv2D)                  (None, 68, 148, 16)   30992       Conv0[0][0]
____________________________________________________________________________________________________
Pooling2E (MaxPooling2D)         (None, 12, 32, 32)    0           dropout_6[0][0]
____________________________________________________________________________________________________
dropout_9 (Dropout)              (None, 12, 32, 64)    0           Deconv1F[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 76, 156, 16)   0           Conv1A[0][0]
____________________________________________________________________________________________________
UpSampling1B (UpSampling2D)      (None, 36, 76, 32)    0           Pooling2B[0][0]
____________________________________________________________________________________________________
UpSampling2C (UpSampling2D)      (None, 36, 76, 64)    0           dropout_13[0][0]
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 68, 148, 16)   0           Conv1D[0][0]
____________________________________________________________________________________________________
UpSampling1E (UpSampling2D)      (None, 24, 64, 32)    0           Pooling2E[0][0]
____________________________________________________________________________________________________
UpSampling2F (UpSampling2D)      (None, 24, 64, 64)    0           dropout_9[0][0]
____________________________________________________________________________________________________
Pooling1A (MaxPooling2D)         (None, 38, 78, 16)    0           dropout_1[0][0]
____________________________________________________________________________________________________
Deconv1B (Conv2DTranspose)       (None, 38, 78, 32)    9248        UpSampling1B[0][0]
____________________________________________________________________________________________________
Deconv2C (Conv2DTranspose)       (None, 38, 78, 32)    18464       UpSampling2C[0][0]
____________________________________________________________________________________________________
Pooling1D (MaxPooling2D)         (None, 34, 74, 16)    0           dropout_5[0][0]
____________________________________________________________________________________________________
Deconv1E (Conv2DTranspose)       (None, 34, 74, 32)    123936      UpSampling1E[0][0]
____________________________________________________________________________________________________
Deconv2F (Conv2DTranspose)       (None, 34, 74, 32)    247840      UpSampling2F[0][0]
____________________________________________________________________________________________________
UpSampling1A (UpSampling2D)      (None, 76, 156, 16)   0           Pooling1A[0][0]
____________________________________________________________________________________________________
dropout_15 (Dropout)             (None, 38, 78, 32)    0           Deconv1B[0][0]
____________________________________________________________________________________________________
dropout_14 (Dropout)             (None, 38, 78, 32)    0           Deconv2C[0][0]
____________________________________________________________________________________________________
UpSampling1D (UpSampling2D)      (None, 68, 148, 16)   0           Pooling1D[0][0]
____________________________________________________________________________________________________
dropout_11 (Dropout)             (None, 34, 74, 32)    0           Deconv1E[0][0]
____________________________________________________________________________________________________
dropout_10 (Dropout)             (None, 34, 74, 32)    0           Deconv2F[0][0]
____________________________________________________________________________________________________
Deconv1A (Conv2DTranspose)       (None, 78, 158, 16)   2320        UpSampling1A[0][0]
____________________________________________________________________________________________________
UpSampling2B (UpSampling2D)      (None, 76, 156, 32)   0           dropout_15[0][0]
____________________________________________________________________________________________________
UpSampling3C (UpSampling2D)      (None, 76, 156, 32)   0           dropout_14[0][0]
____________________________________________________________________________________________________
Deconv1D (Conv2DTranspose)       (None, 78, 158, 16)   30992       UpSampling1D[0][0]
____________________________________________________________________________________________________
UpSampling2E (UpSampling2D)      (None, 68, 148, 32)   0           dropout_11[0][0]
____________________________________________________________________________________________________
UpSampling3F (UpSampling2D)      (None, 68, 148, 32)   0           dropout_10[0][0]
____________________________________________________________________________________________________
dropout_16 (Dropout)             (None, 78, 158, 16)   0           Deconv1A[0][0]
____________________________________________________________________________________________________
Deconv2B (Conv2DTranspose)       (None, 78, 158, 16)   4624        UpSampling2B[0][0]
____________________________________________________________________________________________________
Deconv3C (Conv2DTranspose)       (None, 78, 158, 16)   4624        UpSampling3C[0][0]
____________________________________________________________________________________________________
dropout_12 (Dropout)             (None, 78, 158, 16)   0           Deconv1D[0][0]
____________________________________________________________________________________________________
Deconv2E (Conv2DTranspose)       (None, 78, 158, 16)   61968       UpSampling2E[0][0]
____________________________________________________________________________________________________
Deconv3F (Conv2DTranspose)       (None, 78, 158, 16)   61968       UpSampling3F[0][0]
____________________________________________________________________________________________________
concatenate_1 (Concatenate)      (None, 78, 158, 96)   0           dropout_16[0][0]
                                                                   Deconv2B[0][0]
                                                                   Deconv3C[0][0]
                                                                   dropout_12[0][0]
                                                                   Deconv2E[0][0]
                                                                   Deconv3F[0][0]
____________________________________________________________________________________________________
Deconv0 (Conv2DTranspose)        (None, 80, 160, 1)    865         concatenate_1[0][0]
====================================================================================================
Total params: 1,599,469
Trainable params: 1,599,463
Non-trainable params: 6
____________________________________________________________________________________________________
Epoch 1/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9530Epoch 00000: saving model to weights_c/weights.00-0.0141-0.9530.hdf5
11487/11487 [==============================] - 268s - loss: 0.0141 - acc: 0.9530
Epoch 2/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9608Epoch 00001: saving model to weights_c/weights.01-0.0055-0.9608.hdf5
11487/11487 [==============================] - 261s - loss: 0.0055 - acc: 0.9608
Epoch 3/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9613Epoch 00002: saving model to weights_c/weights.02-0.0046-0.9613.hdf5
11487/11487 [==============================] - 260s - loss: 0.0046 - acc: 0.9613
Epoch 4/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9617Epoch 00003: saving model to weights_c/weights.03-0.0041-0.9617.hdf5
11487/11487 [==============================] - 256s - loss: 0.0041 - acc: 0.9617
Epoch 5/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9622Epoch 00004: saving model to weights_c/weights.04-0.0036-0.9622.hdf5
11487/11487 [==============================] - 256s - loss: 0.0036 - acc: 0.9622
Epoch 6/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9625Epoch 00005: saving model to weights_c/weights.05-0.0032-0.9625.hdf5
11487/11487 [==============================] - 257s - loss: 0.0032 - acc: 0.9625
Epoch 7/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9627Epoch 00006: saving model to weights_c/weights.06-0.0029-0.9627.hdf5
11487/11487 [==============================] - 256s - loss: 0.0029 - acc: 0.9627
Epoch 8/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9628Epoch 00007: saving model to weights_c/weights.07-0.0027-0.9628.hdf5
11487/11487 [==============================] - 257s - loss: 0.0027 - acc: 0.9628
Epoch 9/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9629Epoch 00008: saving model to weights_c/weights.08-0.0026-0.9629.hdf5
11487/11487 [==============================] - 256s - loss: 0.0026 - acc: 0.9629
Epoch 10/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9630Epoch 00009: saving model to weights_c/weights.09-0.0025-0.9630.hdf5
11487/11487 [==============================] - 256s - loss: 0.0025 - acc: 0.9630
Epoch 11/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9630Epoch 00010: saving model to weights_c/weights.10-0.0024-0.9630.hdf5
11487/11487 [==============================] - 256s - loss: 0.0024 - acc: 0.9630
Epoch 12/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9631Epoch 00011: saving model to weights_c/weights.11-0.0023-0.9631.hdf5
11487/11487 [==============================] - 255s - loss: 0.0023 - acc: 0.9631
Epoch 13/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9632Epoch 00012: saving model to weights_c/weights.12-0.0022-0.9632.hdf5
11487/11487 [==============================] - 255s - loss: 0.0022 - acc: 0.9632
Epoch 14/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9630Epoch 00013: saving model to weights_c/weights.13-0.0025-0.9630.hdf5
11487/11487 [==============================] - 255s - loss: 0.0025 - acc: 0.9630
Epoch 15/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9633Epoch 00014: saving model to weights_c/weights.14-0.0020-0.9633.hdf5
11487/11487 [==============================] - 257s - loss: 0.0020 - acc: 0.9633
Epoch 16/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9634Epoch 00015: saving model to weights_c/weights.15-0.0019-0.9634.hdf5
11487/11487 [==============================] - 258s - loss: 0.0019 - acc: 0.9634
Epoch 17/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9633Epoch 00016: saving model to weights_c/weights.16-0.0020-0.9633.hdf5
11487/11487 [==============================] - 255s - loss: 0.0020 - acc: 0.9633
Epoch 18/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9634Epoch 00017: saving model to weights_c/weights.17-0.0018-0.9634.hdf5
11487/11487 [==============================] - 255s - loss: 0.0018 - acc: 0.9634
Epoch 19/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9634Epoch 00018: saving model to weights_c/weights.18-0.0018-0.9634.hdf5
11487/11487 [==============================] - 255s - loss: 0.0018 - acc: 0.9634
Epoch 20/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00019: saving model to weights_c/weights.19-0.0018-0.9635.hdf5
11487/11487 [==============================] - 255s - loss: 0.0018 - acc: 0.9635
Epoch 21/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9635Epoch 00020: saving model to weights_c/weights.20-0.0017-0.9635.hdf5
11487/11487 [==============================] - 254s - loss: 0.0017 - acc: 0.9635
Epoch 22/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9635Epoch 00021: saving model to weights_c/weights.21-0.0017-0.9635.hdf5
11487/11487 [==============================] - 255s - loss: 0.0017 - acc: 0.9635
Epoch 23/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9636Epoch 00022: saving model to weights_c/weights.22-0.0016-0.9636.hdf5
11487/11487 [==============================] - 257s - loss: 0.0016 - acc: 0.9636
Epoch 24/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9636Epoch 00023: saving model to weights_c/weights.23-0.0016-0.9636.hdf5
11487/11487 [==============================] - 256s - loss: 0.0016 - acc: 0.9636
Epoch 25/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9636Epoch 00024: saving model to weights_c/weights.24-0.0015-0.9636.hdf5
11487/11487 [==============================] - 255s - loss: 0.0015 - acc: 0.9636
Epoch 26/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9636Epoch 00025: saving model to weights_c/weights.25-0.0015-0.9636.hdf5
11487/11487 [==============================] - 255s - loss: 0.0015 - acc: 0.9636
Epoch 27/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9636Epoch 00026: saving model to weights_c/weights.26-0.0015-0.9636.hdf5
11487/11487 [==============================] - 255s - loss: 0.0015 - acc: 0.9636
Epoch 28/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9637Epoch 00027: saving model to weights_c/weights.27-0.0014-0.9637.hdf5
11487/11487 [==============================] - 254s - loss: 0.0014 - acc: 0.9637
Epoch 29/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9637Epoch 00028: saving model to weights_c/weights.28-0.0014-0.9637.hdf5
11487/11487 [==============================] - 254s - loss: 0.0014 - acc: 0.9637
Epoch 30/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9637Epoch 00029: saving model to weights_c/weights.29-0.0014-0.9637.hdf5
11487/11487 [==============================] - 254s - loss: 0.0014 - acc: 0.9637
Epoch 31/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9637Epoch 00030: saving model to weights_c/weights.30-0.0014-0.9637.hdf5
11487/11487 [==============================] - 255s - loss: 0.0014 - acc: 0.9637
Epoch 32/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9637Epoch 00031: saving model to weights_c/weights.31-0.0013-0.9637.hdf5
11487/11487 [==============================] - 256s - loss: 0.0013 - acc: 0.9637
Epoch 33/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00032: saving model to weights_c/weights.32-0.0013-0.9638.hdf5
11487/11487 [==============================] - 260s - loss: 0.0013 - acc: 0.9638
Epoch 34/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00033: saving model to weights_c/weights.33-0.0013-0.9638.hdf5
11487/11487 [==============================] - 255s - loss: 0.0013 - acc: 0.9638
Epoch 35/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9638Epoch 00034: saving model to weights_c/weights.34-0.0013-0.9638.hdf5
11487/11487 [==============================] - 259s - loss: 0.0013 - acc: 0.9638
Epoch 36/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9638Epoch 00035: saving model to weights_c/weights.35-0.0012-0.9638.hdf5
11487/11487 [==============================] - 255s - loss: 0.0012 - acc: 0.9638
Epoch 37/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9638Epoch 00036: saving model to weights_c/weights.36-0.0012-0.9638.hdf5
11487/11487 [==============================] - 255s - loss: 0.0012 - acc: 0.9638
Epoch 38/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9638Epoch 00037: saving model to weights_c/weights.37-0.0012-0.9638.hdf5
11487/11487 [==============================] - 255s - loss: 0.0012 - acc: 0.9638
Epoch 39/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9638Epoch 00038: saving model to weights_c/weights.38-0.0012-0.9638.hdf5
11487/11487 [==============================] - 255s - loss: 0.0012 - acc: 0.9638
Epoch 40/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9638Epoch 00039: saving model to weights_c/weights.39-0.0012-0.9638.hdf5
11487/11487 [==============================] - 255s - loss: 0.0012 - acc: 0.9638
Epoch 41/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9639Epoch 00040: saving model to weights_c/weights.40-0.0011-0.9639.hdf5
11487/11487 [==============================] - 255s - loss: 0.0011 - acc: 0.9639
Epoch 42/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9638Epoch 00041: saving model to weights_c/weights.41-0.0012-0.9638.hdf5
11487/11487 [==============================] - 255s - loss: 0.0012 - acc: 0.9638
Epoch 43/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9638Epoch 00042: saving model to weights_c/weights.42-0.0011-0.9638.hdf5
11487/11487 [==============================] - 255s - loss: 0.0011 - acc: 0.9638
Epoch 44/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9638Epoch 00043: saving model to weights_c/weights.43-0.0011-0.9638.hdf5
11487/11487 [==============================] - 255s - loss: 0.0011 - acc: 0.9638
Epoch 45/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9639Epoch 00044: saving model to weights_c/weights.44-0.0011-0.9639.hdf5
11487/11487 [==============================] - 254s - loss: 0.0011 - acc: 0.9639
Epoch 46/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9639Epoch 00045: saving model to weights_c/weights.45-0.0011-0.9639.hdf5
11487/11487 [==============================] - 254s - loss: 0.0011 - acc: 0.9639
Epoch 47/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 0.9639Epoch 00046: saving model to weights_c/weights.46-0.0010-0.9639.hdf5
11487/11487 [==============================] - 255s - loss: 0.0010 - acc: 0.9639
Epoch 48/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9639Epoch 00047: saving model to weights_c/weights.47-0.0011-0.9639.hdf5
11487/11487 [==============================] - 255s - loss: 0.0011 - acc: 0.9639
Epoch 49/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 0.9639Epoch 00048: saving model to weights_c/weights.48-0.0010-0.9639.hdf5
11487/11487 [==============================] - 255s - loss: 0.0010 - acc: 0.9639
Epoch 50/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 0.9639Epoch 00049: saving model to weights_c/weights.49-0.0010-0.9639.hdf5
11487/11487 [==============================] - 255s - loss: 0.0010 - acc: 0.9639
Epoch 51/100
11480/11487 [============================>.] - ETA: 0s - loss: 9.9125e-04 - acc: 0.9639Epoch 00050: saving model to weights_c/weights.50-0.0010-0.9639.hdf5
11487/11487 [==============================] - 255s - loss: 9.9121e-04 - acc: 0.9639
Epoch 52/100
11480/11487 [============================>.] - ETA: 0s - loss: 9.9223e-04 - acc: 0.9639Epoch 00051: saving model to weights_c/weights.51-0.0010-0.9639.hdf5
11487/11487 [==============================] - 254s - loss: 9.9233e-04 - acc: 0.9639
Epoch 53/100
11480/11487 [============================>.] - ETA: 0s - loss: 9.8538e-04 - acc: 0.9639Epoch 00052: saving model to weights_c/weights.52-0.0010-0.9639.hdf5
11487/11487 [==============================] - 254s - loss: 9.8593e-04 - acc: 0.9639
Epoch 54/100
11480/11487 [============================>.] - ETA: 0s - loss: 9.6267e-04 - acc: 0.9639Epoch 00053: saving model to weights_c/weights.53-0.0010-0.9639.hdf5
11487/11487 [==============================] - 254s - loss: 9.6259e-04 - acc: 0.9639
Epoch 55/100
11480/11487 [============================>.] - ETA: 0s - loss: 9.9723e-04 - acc: 0.9639Epoch 00054: saving model to weights_c/weights.54-0.0010-0.9639.hdf5
11487/11487 [==============================] - 254s - loss: 9.9746e-04 - acc: 0.9639
Epoch 56/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9639Epoch 00055: saving model to weights_c/weights.55-0.0011-0.9639.hdf5
11487/11487 [==============================] - 254s - loss: 0.0011 - acc: 0.9639
Epoch 57/100
11480/11487 [============================>.] - ETA: 0s - loss: 9.5657e-04 - acc: 0.9639Epoch 00056: saving model to weights_c/weights.56-0.0010-0.9639.hdf5
11487/11487 [==============================] - 255s - loss: 9.5634e-04 - acc: 0.9639
Epoch 58/100
11480/11487 [============================>.] - ETA: 0s - loss: 9.1579e-04 - acc: 0.9640Epoch 00057: saving model to weights_c/weights.57-0.0009-0.9640.hdf5
11487/11487 [==============================] - 254s - loss: 9.1586e-04 - acc: 0.9640
Epoch 59/100
11480/11487 [============================>.] - ETA: 0s - loss: 9.0413e-04 - acc: 0.9640Epoch 00058: saving model to weights_c/weights.58-0.0009-0.9640.hdf5
11487/11487 [==============================] - 254s - loss: 9.0421e-04 - acc: 0.9640
Epoch 60/100
11480/11487 [============================>.] - ETA: 0s - loss: 8.9635e-04 - acc: 0.9640Epoch 00059: saving model to weights_c/weights.59-0.0009-0.9640.hdf5
11487/11487 [==============================] - 255s - loss: 8.9631e-04 - acc: 0.9640
Epoch 61/100
11480/11487 [============================>.] - ETA: 0s - loss: 8.9149e-04 - acc: 0.9640Epoch 00060: saving model to weights_c/weights.60-0.0009-0.9640.hdf5
11487/11487 [==============================] - 255s - loss: 8.9208e-04 - acc: 0.9640
Epoch 62/100
11480/11487 [============================>.] - ETA: 0s - loss: 8.7875e-04 - acc: 0.9640Epoch 00061: saving model to weights_c/weights.61-0.0009-0.9640.hdf5
11487/11487 [==============================] - 255s - loss: 8.7875e-04 - acc: 0.9640
Epoch 63/100
11480/11487 [============================>.] - ETA: 0s - loss: 9.2892e-04 - acc: 0.9639Epoch 00062: saving model to weights_c/weights.62-0.0009-0.9639.hdf5
11487/11487 [==============================] - 256s - loss: 9.2900e-04 - acc: 0.9639
Epoch 64/100
11480/11487 [============================>.] - ETA: 0s - loss: 8.5913e-04 - acc: 0.9640Epoch 00063: saving model to weights_c/weights.63-0.0009-0.9640.hdf5
11487/11487 [==============================] - 256s - loss: 8.5901e-04 - acc: 0.9640
Epoch 65/100
11480/11487 [============================>.] - ETA: 0s - loss: 8.6463e-04 - acc: 0.9640Epoch 00064: saving model to weights_c/weights.64-0.0009-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 8.6449e-04 - acc: 0.9640
Epoch 66/100
11480/11487 [============================>.] - ETA: 0s - loss: 8.6739e-04 - acc: 0.9640Epoch 00065: saving model to weights_c/weights.65-0.0009-0.9640.hdf5
11487/11487 [==============================] - 254s - loss: 8.6747e-04 - acc: 0.9640
Epoch 67/100
11480/11487 [============================>.] - ETA: 0s - loss: 8.9119e-04 - acc: 0.9640Epoch 00066: saving model to weights_c/weights.66-0.0009-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 8.9143e-04 - acc: 0.9640
Epoch 68/100
11480/11487 [============================>.] - ETA: 0s - loss: 8.4453e-04 - acc: 0.9640Epoch 00067: saving model to weights_c/weights.67-0.0008-0.9640.hdf5
11487/11487 [==============================] - 254s - loss: 8.4447e-04 - acc: 0.9640
Epoch 69/100
11480/11487 [============================>.] - ETA: 0s - loss: 8.6760e-04 - acc: 0.9640Epoch 00068: saving model to weights_c/weights.68-0.0009-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 8.6747e-04 - acc: 0.9640
Epoch 70/100
11480/11487 [============================>.] - ETA: 0s - loss: 8.3356e-04 - acc: 0.9640Epoch 00069: saving model to weights_c/weights.69-0.0008-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 8.3364e-04 - acc: 0.9640
Epoch 71/100
11480/11487 [============================>.] - ETA: 0s - loss: 8.6987e-04 - acc: 0.9640Epoch 00070: saving model to weights_c/weights.70-0.0009-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 8.6995e-04 - acc: 0.9640
Epoch 72/100
11480/11487 [============================>.] - ETA: 0s - loss: 8.1891e-04 - acc: 0.9640Epoch 00071: saving model to weights_c/weights.71-0.0008-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 8.1901e-04 - acc: 0.9640
Epoch 73/100
11480/11487 [============================>.] - ETA: 0s - loss: 8.1318e-04 - acc: 0.9640Epoch 00072: saving model to weights_c/weights.72-0.0008-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 8.1329e-04 - acc: 0.9640
Epoch 74/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.9400e-04 - acc: 0.9640Epoch 00073: saving model to weights_c/weights.73-0.0008-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.9385e-04 - acc: 0.9640
Epoch 75/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.9788e-04 - acc: 0.9640Epoch 00074: saving model to weights_c/weights.74-0.0008-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.9900e-04 - acc: 0.9640
Epoch 76/100
11480/11487 [============================>.] - ETA: 0s - loss: 9.2080e-04 - acc: 0.9639Epoch 00075: saving model to weights_c/weights.75-0.0009-0.9639.hdf5
11487/11487 [==============================] - 253s - loss: 9.2076e-04 - acc: 0.9639
Epoch 77/100
11480/11487 [============================>.] - ETA: 0s - loss: 8.0334e-04 - acc: 0.9640Epoch 00076: saving model to weights_c/weights.76-0.0008-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 8.0325e-04 - acc: 0.9640
Epoch 78/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.7398e-04 - acc: 0.9640Epoch 00077: saving model to weights_c/weights.77-0.0008-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.7397e-04 - acc: 0.9640
Epoch 79/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.6636e-04 - acc: 0.9640Epoch 00078: saving model to weights_c/weights.78-0.0008-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.6667e-04 - acc: 0.9640
Epoch 80/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.5560e-04 - acc: 0.9640Epoch 00079: saving model to weights_c/weights.79-0.0008-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.5548e-04 - acc: 0.9640
Epoch 81/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.5748e-04 - acc: 0.9640Epoch 00080: saving model to weights_c/weights.80-0.0008-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.5764e-04 - acc: 0.9640
Epoch 82/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.2870e-04 - acc: 0.9640Epoch 00081: saving model to weights_c/weights.81-0.0007-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.2871e-04 - acc: 0.9640
Epoch 83/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.6448e-04 - acc: 0.9640Epoch 00082: saving model to weights_c/weights.82-0.0008-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.6436e-04 - acc: 0.9640
Epoch 84/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.5761e-04 - acc: 0.9640Epoch 00083: saving model to weights_c/weights.83-0.0008-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.5826e-04 - acc: 0.9640
Epoch 85/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.7171e-04 - acc: 0.9640Epoch 00084: saving model to weights_c/weights.84-0.0008-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.7168e-04 - acc: 0.9640
Epoch 86/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.1685e-04 - acc: 0.9640Epoch 00085: saving model to weights_c/weights.85-0.0007-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.1697e-04 - acc: 0.9640
Epoch 87/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.4954e-04 - acc: 0.9640Epoch 00086: saving model to weights_c/weights.86-0.0007-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.4969e-04 - acc: 0.9640
Epoch 88/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.1768e-04 - acc: 0.9640Epoch 00087: saving model to weights_c/weights.87-0.0007-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.1757e-04 - acc: 0.9640
Epoch 89/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.2960e-04 - acc: 0.9640Epoch 00088: saving model to weights_c/weights.88-0.0007-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.2969e-04 - acc: 0.9640
Epoch 90/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.5486e-04 - acc: 0.9640Epoch 00089: saving model to weights_c/weights.89-0.0008-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.5487e-04 - acc: 0.9640
Epoch 91/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.1356e-04 - acc: 0.9640Epoch 00090: saving model to weights_c/weights.90-0.0007-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.1362e-04 - acc: 0.9640
Epoch 92/100
11480/11487 [============================>.] - ETA: 0s - loss: 6.9934e-04 - acc: 0.9641Epoch 00091: saving model to weights_c/weights.91-0.0007-0.9641.hdf5
11487/11487 [==============================] - 253s - loss: 6.9934e-04 - acc: 0.9641
Epoch 93/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.2827e-04 - acc: 0.9640Epoch 00092: saving model to weights_c/weights.92-0.0007-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.2815e-04 - acc: 0.9640
Epoch 94/100
11480/11487 [============================>.] - ETA: 0s - loss: 6.8593e-04 - acc: 0.9641Epoch 00093: saving model to weights_c/weights.93-0.0007-0.9641.hdf5
11487/11487 [==============================] - 253s - loss: 6.8604e-04 - acc: 0.9641
Epoch 95/100
11480/11487 [============================>.] - ETA: 0s - loss: 6.7545e-04 - acc: 0.9641Epoch 00094: saving model to weights_c/weights.94-0.0007-0.9641.hdf5
11487/11487 [==============================] - 253s - loss: 6.7538e-04 - acc: 0.9641
Epoch 96/100
11480/11487 [============================>.] - ETA: 0s - loss: 7.1681e-04 - acc: 0.9640Epoch 00095: saving model to weights_c/weights.95-0.0007-0.9640.hdf5
11487/11487 [==============================] - 253s - loss: 7.1679e-04 - acc: 0.9640
Epoch 97/100
11480/11487 [============================>.] - ETA: 0s - loss: 6.8762e-04 - acc: 0.9641Epoch 00096: saving model to weights_c/weights.96-0.0007-0.9641.hdf5
11487/11487 [==============================] - 253s - loss: 6.8775e-04 - acc: 0.9641
Epoch 98/100
11480/11487 [============================>.] - ETA: 0s - loss: 6.7234e-04 - acc: 0.9641Epoch 00097: saving model to weights_c/weights.97-0.0007-0.9641.hdf5
11487/11487 [==============================] - 253s - loss: 6.7220e-04 - acc: 0.9641
Epoch 99/100
11480/11487 [============================>.] - ETA: 0s - loss: 6.7660e-04 - acc: 0.9641Epoch 00098: saving model to weights_c/weights.98-0.0007-0.9641.hdf5
11487/11487 [==============================] - 253s - loss: 6.7656e-04 - acc: 0.9641
Epoch 100/100
11480/11487 [============================>.] - ETA: 0s - loss: 6.8033e-04 - acc: 0.9641Epoch 00099: saving model to weights_c/weights.99-0.0007-0.9641.hdf5
11487/11487 [==============================] - 253s - loss: 6.8030e-04 - acc: 0.9641
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_1 (InputLayer)             (None, 80, 160, 3)    0
____________________________________________________________________________________________________
batch_normalization_1 (BatchNorm (None, 80, 160, 3)    12          input_1[0][0]
____________________________________________________________________________________________________
Conv0 (Conv2D)                   (None, 78, 158, 16)   448         batch_normalization_1[0][0]
____________________________________________________________________________________________________
Conv1C (Conv2D)                  (None, 76, 156, 16)   2320        Conv0[0][0]
____________________________________________________________________________________________________
Conv1F (Conv2D)                  (None, 68, 148, 16)   30992       Conv0[0][0]
____________________________________________________________________________________________________
Pooling1C (MaxPooling2D)         (None, 38, 78, 16)    0           Conv1C[0][0]
____________________________________________________________________________________________________
Pooling1F (MaxPooling2D)         (None, 34, 74, 16)    0           Conv1F[0][0]
____________________________________________________________________________________________________
Conv2C (Conv2D)                  (None, 36, 76, 32)    4640        Pooling1C[0][0]
____________________________________________________________________________________________________
Conv2F (Conv2D)                  (None, 24, 64, 32)    61984       Pooling1F[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 36, 76, 32)    0           Conv2C[0][0]
____________________________________________________________________________________________________
dropout_7 (Dropout)              (None, 24, 64, 32)    0           Conv2F[0][0]
____________________________________________________________________________________________________
Pooling2C (MaxPooling2D)         (None, 18, 38, 32)    0           dropout_3[0][0]
____________________________________________________________________________________________________
Pooling2F (MaxPooling2D)         (None, 12, 32, 32)    0           dropout_7[0][0]
____________________________________________________________________________________________________
Conv3C (Conv2D)                  (None, 16, 36, 64)    18496       Pooling2C[0][0]
____________________________________________________________________________________________________
Conv3F (Conv2D)                  (None, 2, 22, 64)     247872      Pooling2F[0][0]
____________________________________________________________________________________________________
Conv1B (Conv2D)                  (None, 76, 156, 16)   2320        Conv0[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 16, 36, 64)    0           Conv3C[0][0]
____________________________________________________________________________________________________
Conv1E (Conv2D)                  (None, 68, 148, 16)   30992       Conv0[0][0]
____________________________________________________________________________________________________
dropout_8 (Dropout)              (None, 2, 22, 64)     0           Conv3F[0][0]
____________________________________________________________________________________________________
Pooling1B (MaxPooling2D)         (None, 38, 78, 16)    0           Conv1B[0][0]
____________________________________________________________________________________________________
Pooling3C (MaxPooling2D)         (None, 8, 18, 64)     0           dropout_4[0][0]
____________________________________________________________________________________________________
Pooling1E (MaxPooling2D)         (None, 34, 74, 16)    0           Conv1E[0][0]
____________________________________________________________________________________________________
Pooling3F (MaxPooling2D)         (None, 1, 11, 64)     0           dropout_8[0][0]
____________________________________________________________________________________________________
Conv2B (Conv2D)                  (None, 36, 76, 32)    4640        Pooling1B[0][0]
____________________________________________________________________________________________________
UpSampling1C (UpSampling2D)      (None, 16, 36, 64)    0           Pooling3C[0][0]
____________________________________________________________________________________________________
Conv2E (Conv2D)                  (None, 24, 64, 32)    61984       Pooling1E[0][0]
____________________________________________________________________________________________________
UpSampling1F (UpSampling2D)      (None, 2, 22, 64)     0           Pooling3F[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 36, 76, 32)    0           Conv2B[0][0]
____________________________________________________________________________________________________
Deconv1C (Conv2DTranspose)       (None, 18, 38, 64)    36928       UpSampling1C[0][0]
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 24, 64, 32)    0           Conv2E[0][0]
____________________________________________________________________________________________________
Deconv1F (Conv2DTranspose)       (None, 12, 32, 64)    495680      UpSampling1F[0][0]
____________________________________________________________________________________________________
Conv1A (Conv2D)                  (None, 76, 156, 16)   2320        Conv0[0][0]
____________________________________________________________________________________________________
Pooling2B (MaxPooling2D)         (None, 18, 38, 32)    0           dropout_2[0][0]
____________________________________________________________________________________________________
dropout_13 (Dropout)             (None, 18, 38, 64)    0           Deconv1C[0][0]
____________________________________________________________________________________________________
Conv1D (Conv2D)                  (None, 68, 148, 16)   30992       Conv0[0][0]
____________________________________________________________________________________________________
Pooling2E (MaxPooling2D)         (None, 12, 32, 32)    0           dropout_6[0][0]
____________________________________________________________________________________________________
dropout_9 (Dropout)              (None, 12, 32, 64)    0           Deconv1F[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 76, 156, 16)   0           Conv1A[0][0]
____________________________________________________________________________________________________
UpSampling1B (UpSampling2D)      (None, 36, 76, 32)    0           Pooling2B[0][0]
____________________________________________________________________________________________________
UpSampling2C (UpSampling2D)      (None, 36, 76, 64)    0           dropout_13[0][0]
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 68, 148, 16)   0           Conv1D[0][0]
____________________________________________________________________________________________________
UpSampling1E (UpSampling2D)      (None, 24, 64, 32)    0           Pooling2E[0][0]
____________________________________________________________________________________________________
UpSampling2F (UpSampling2D)      (None, 24, 64, 64)    0           dropout_9[0][0]
____________________________________________________________________________________________________
Pooling1A (MaxPooling2D)         (None, 38, 78, 16)    0           dropout_1[0][0]
____________________________________________________________________________________________________
Deconv1B (Conv2DTranspose)       (None, 38, 78, 32)    9248        UpSampling1B[0][0]
____________________________________________________________________________________________________
Deconv2C (Conv2DTranspose)       (None, 38, 78, 32)    18464       UpSampling2C[0][0]
____________________________________________________________________________________________________
Pooling1D (MaxPooling2D)         (None, 34, 74, 16)    0           dropout_5[0][0]
____________________________________________________________________________________________________
Deconv1E (Conv2DTranspose)       (None, 34, 74, 32)    123936      UpSampling1E[0][0]
____________________________________________________________________________________________________
Deconv2F (Conv2DTranspose)       (None, 34, 74, 32)    247840      UpSampling2F[0][0]
____________________________________________________________________________________________________
UpSampling1A (UpSampling2D)      (None, 76, 156, 16)   0           Pooling1A[0][0]
____________________________________________________________________________________________________
dropout_15 (Dropout)             (None, 38, 78, 32)    0           Deconv1B[0][0]
____________________________________________________________________________________________________
dropout_14 (Dropout)             (None, 38, 78, 32)    0           Deconv2C[0][0]
____________________________________________________________________________________________________
UpSampling1D (UpSampling2D)      (None, 68, 148, 16)   0           Pooling1D[0][0]
____________________________________________________________________________________________________
dropout_11 (Dropout)             (None, 34, 74, 32)    0           Deconv1E[0][0]
____________________________________________________________________________________________________
dropout_10 (Dropout)             (None, 34, 74, 32)    0           Deconv2F[0][0]
____________________________________________________________________________________________________
Deconv1A (Conv2DTranspose)       (None, 78, 158, 16)   2320        UpSampling1A[0][0]
____________________________________________________________________________________________________
UpSampling2B (UpSampling2D)      (None, 76, 156, 32)   0           dropout_15[0][0]
____________________________________________________________________________________________________
UpSampling3C (UpSampling2D)      (None, 76, 156, 32)   0           dropout_14[0][0]
____________________________________________________________________________________________________
Deconv1D (Conv2DTranspose)       (None, 78, 158, 16)   30992       UpSampling1D[0][0]
____________________________________________________________________________________________________
UpSampling2E (UpSampling2D)      (None, 68, 148, 32)   0           dropout_11[0][0]
____________________________________________________________________________________________________
UpSampling3F (UpSampling2D)      (None, 68, 148, 32)   0           dropout_10[0][0]
____________________________________________________________________________________________________
dropout_16 (Dropout)             (None, 78, 158, 16)   0           Deconv1A[0][0]
____________________________________________________________________________________________________
Deconv2B (Conv2DTranspose)       (None, 78, 158, 16)   4624        UpSampling2B[0][0]
____________________________________________________________________________________________________
Deconv3C (Conv2DTranspose)       (None, 78, 158, 16)   4624        UpSampling3C[0][0]
____________________________________________________________________________________________________
dropout_12 (Dropout)             (None, 78, 158, 16)   0           Deconv1D[0][0]
____________________________________________________________________________________________________
Deconv2E (Conv2DTranspose)       (None, 78, 158, 16)   61968       UpSampling2E[0][0]
____________________________________________________________________________________________________
Deconv3F (Conv2DTranspose)       (None, 78, 158, 16)   61968       UpSampling3F[0][0]
____________________________________________________________________________________________________
concatenate_1 (Concatenate)      (None, 78, 158, 96)   0           dropout_16[0][0]
                                                                   Deconv2B[0][0]
                                                                   Deconv3C[0][0]
                                                                   dropout_12[0][0]
                                                                   Deconv2E[0][0]
                                                                   Deconv3F[0][0]
____________________________________________________________________________________________________
Deconv0 (Conv2DTranspose)        (None, 80, 160, 1)    865         concatenate_1[0][0]
====================================================================================================
Total params: 1,599,469
Trainable params: 1,599,463
Non-trainable params: 6
____________________________________________________________________________________________________