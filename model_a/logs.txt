Using TensorFlow backend.
X: (11487, 80, 160, 3) -> Y: (11487, 80, 160, 1)
2017-12-16 03:06:59.293171: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-16 03:06:59.293197: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-16 03:06:59.293204: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-16 03:06:59.293227: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, butthese are available on your machine and could speed up CPU computations.
2017-12-16 03:06:59.293232: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-16 03:06:59.394708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-12-16 03:06:59.395030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX 1050 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.62
pciBusID 0000:01:00.0
Total memory: 3.94GiB
Free memory: 3.29GiB
2017-12-16 03:06:59.395072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-12-16 03:06:59.395104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-12-16 03:06:59.395114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0)
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_1 (InputLayer)             (None, 80, 160, 3)    0
____________________________________________________________________________________________________
batch_normalization_1 (BatchNorm (None, 80, 160, 3)    12          input_1[0][0]
____________________________________________________________________________________________________
Conv0 (Conv2D)                   (None, 78, 158, 8)    224         batch_normalization_1[0][0]
____________________________________________________________________________________________________
Conv1C (Conv2D)                  (None, 76, 156, 16)   1168        Conv0[0][0]
____________________________________________________________________________________________________
Pooling1C (MaxPooling2D)         (None, 38, 78, 16)    0           Conv1C[0][0]
____________________________________________________________________________________________________
Conv2C (Conv2D)                  (None, 36, 76, 32)    4640        Pooling1C[0][0]
____________________________________________________________________________________________________
Pooling2C (MaxPooling2D)         (None, 18, 38, 32)    0           Conv2C[0][0]
____________________________________________________________________________________________________
Conv1B (Conv2D)                  (None, 76, 156, 16)   1168        Conv0[0][0]
____________________________________________________________________________________________________
Conv3C (Conv2D)                  (None, 16, 36, 64)    18496       Pooling2C[0][0]
____________________________________________________________________________________________________
Pooling1B (MaxPooling2D)         (None, 38, 78, 16)    0           Conv1B[0][0]
____________________________________________________________________________________________________
Pooling3C (MaxPooling2D)         (None, 8, 18, 64)     0           Conv3C[0][0]
____________________________________________________________________________________________________
Conv2B (Conv2D)                  (None, 36, 76, 32)    4640        Pooling1B[0][0]
____________________________________________________________________________________________________
UpSampling1C (UpSampling2D)      (None, 16, 36, 64)    0           Pooling3C[0][0]
____________________________________________________________________________________________________
Pooling2B (MaxPooling2D)         (None, 18, 38, 32)    0           Conv2B[0][0]
____________________________________________________________________________________________________
Deconv1C (Conv2DTranspose)       (None, 18, 38, 64)    36928       UpSampling1C[0][0]
____________________________________________________________________________________________________
Conv1A (Conv2D)                  (None, 76, 156, 16)   1168        Conv0[0][0]
____________________________________________________________________________________________________
UpSampling1B (UpSampling2D)      (None, 36, 76, 32)    0           Pooling2B[0][0]
____________________________________________________________________________________________________
UpSampling2C (UpSampling2D)      (None, 36, 76, 64)    0           Deconv1C[0][0]
____________________________________________________________________________________________________
Pooling1A (MaxPooling2D)         (None, 38, 78, 16)    0           Conv1A[0][0]
____________________________________________________________________________________________________
Deconv1B (Conv2DTranspose)       (None, 38, 78, 32)    9248        UpSampling1B[0][0]
____________________________________________________________________________________________________
Deconv2C (Conv2DTranspose)       (None, 38, 78, 32)    18464       UpSampling2C[0][0]
____________________________________________________________________________________________________
UpSampling1A (UpSampling2D)      (None, 76, 156, 16)   0           Pooling1A[0][0]
____________________________________________________________________________________________________
UpSampling2B (UpSampling2D)      (None, 76, 156, 32)   0           Deconv1B[0][0]
____________________________________________________________________________________________________
UpSampling3C (UpSampling2D)      (None, 76, 156, 32)   0           Deconv2C[0][0]
____________________________________________________________________________________________________
Deconv1A (Conv2DTranspose)       (None, 78, 158, 16)   2320        UpSampling1A[0][0]
____________________________________________________________________________________________________
Deconv2B (Conv2DTranspose)       (None, 78, 158, 16)   4624        UpSampling2B[0][0]
____________________________________________________________________________________________________
Deconv3C (Conv2DTranspose)       (None, 78, 158, 16)   4624        UpSampling3C[0][0]
____________________________________________________________________________________________________
concatenate_1 (Concatenate)      (None, 78, 158, 48)   0           Deconv1A[0][0]
                                                                   Deconv2B[0][0]
                                                                   Deconv3C[0][0]
____________________________________________________________________________________________________
Deconv0 (Conv2DTranspose)        (None, 80, 160, 1)    433         concatenate_1[0][0]
====================================================================================================
Total params: 108,157
Trainable params: 108,151
Non-trainable params: 6
____________________________________________________________________________________________________
Epoch 1/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9462Epoch 00000: saving model to weights/weights.00-0.02.hdf5
11487/11487 [==============================] - 85s - loss: 0.0191 - acc: 0.9462
Epoch 2/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9583Epoch 00001: saving model to weights/weights.01-0.01.hdf5
11487/11487 [==============================] - 72s - loss: 0.0079 - acc: 0.9583
Epoch 3/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9595Epoch 00002: saving model to weights/weights.02-0.01.hdf5
11487/11487 [==============================] - 73s - loss: 0.0066 - acc: 0.9595
Epoch 4/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9601Epoch 00003: saving model to weights/weights.03-0.01.hdf5
11487/11487 [==============================] - 72s - loss: 0.0059 - acc: 0.9601
Epoch 5/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9605Epoch 00004: saving model to weights/weights.04-0.01.hdf5
11487/11487 [==============================] - 72s - loss: 0.0054 - acc: 0.9605
Epoch 6/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9608Epoch 00005: saving model to weights/weights.05-0.01.hdf5
11487/11487 [==============================] - 73s - loss: 0.0051 - acc: 0.9608
Epoch 7/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9608Epoch 00006: saving model to weights/weights.06-0.01.hdf5
11487/11487 [==============================] - 77s - loss: 0.0050 - acc: 0.9608
Epoch 8/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9612Epoch 00007: saving model to weights/weights.07-0.00.hdf5
11487/11487 [==============================] - 77s - loss: 0.0046 - acc: 0.9612
Epoch 9/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9612Epoch 00008: saving model to weights/weights.08-0.00.hdf5
11487/11487 [==============================] - 77s - loss: 0.0046 - acc: 0.9612
Epoch 10/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9614Epoch 00009: saving model to weights/weights.09-0.00.hdf5
11487/11487 [==============================] - 77s - loss: 0.0044 - acc: 0.9614
Epoch 11/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9614Epoch 00010: saving model to weights/weights.10-0.00.hdf5
11487/11487 [==============================] - 77s - loss: 0.0043 - acc: 0.9614
Epoch 12/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9616Epoch 00011: saving model to weights/weights.11-0.00.hdf5
11487/11487 [==============================] - 74s - loss: 0.0041 - acc: 0.9616
Epoch 13/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9617Epoch 00012: saving model to weights/weights.12-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0040 - acc: 0.9617
Epoch 14/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9618Epoch 00013: saving model to weights/weights.13-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0039 - acc: 0.9618
Epoch 15/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9619Epoch 00014: saving model to weights/weights.14-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0038 - acc: 0.9619
Epoch 16/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9620Epoch 00015: saving model to weights/weights.15-0.00.hdf5
11487/11487 [==============================] - 74s - loss: 0.0036 - acc: 0.9620
Epoch 17/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9620Epoch 00016: saving model to weights/weights.16-0.00.hdf5
11487/11487 [==============================] - 73s - loss: 0.0036 - acc: 0.9620
Epoch 18/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9622Epoch 00017: saving model to weights/weights.17-0.00.hdf5
11487/11487 [==============================] - 73s - loss: 0.0035 - acc: 0.9622
Epoch 19/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9622Epoch 00018: saving model to weights/weights.18-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0034 - acc: 0.9622
Epoch 20/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9623Epoch 00019: saving model to weights/weights.19-0.00.hdf5
11487/11487 [==============================] - 73s - loss: 0.0034 - acc: 0.9623
Epoch 21/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9623Epoch 00020: saving model to weights/weights.20-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0033 - acc: 0.9623
Epoch 22/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9624Epoch 00021: saving model to weights/weights.21-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0032 - acc: 0.9624
Epoch 23/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9625Epoch 00022: saving model to weights/weights.22-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0031 - acc: 0.9625
Epoch 24/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9625Epoch 00023: saving model to weights/weights.23-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0031 - acc: 0.9625
Epoch 25/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9626Epoch 00024: saving model to weights/weights.24-0.00.hdf5
11487/11487 [==============================] - 73s - loss: 0.0030 - acc: 0.9626
Epoch 26/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9624Epoch 00025: saving model to weights/weights.25-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0031 - acc: 0.9624
Epoch 27/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9627Epoch 00026: saving model to weights/weights.26-0.00.hdf5
11487/11487 [==============================] - 74s - loss: 0.0029 - acc: 0.9627
Epoch 28/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9625Epoch 00027: saving model to weights/weights.27-0.00.hdf5
11487/11487 [==============================] - 73s - loss: 0.0030 - acc: 0.9625
Epoch 29/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9627Epoch 00028: saving model to weights/weights.28-0.00.hdf5
11487/11487 [==============================] - 74s - loss: 0.0029 - acc: 0.9627
Epoch 30/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9627Epoch 00029: saving model to weights/weights.29-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0028 - acc: 0.9627
Epoch 31/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9627Epoch 00030: saving model to weights/weights.30-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0028 - acc: 0.9627
Epoch 32/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9628Epoch 00031: saving model to weights/weights.31-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0027 - acc: 0.9628
Epoch 33/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9628Epoch 00032: saving model to weights/weights.32-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0027 - acc: 0.9628
Epoch 34/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9629Epoch 00033: saving model to weights/weights.33-0.00.hdf5
11487/11487 [==============================] - 73s - loss: 0.0026 - acc: 0.9629
Epoch 35/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9629Epoch 00034: saving model to weights/weights.34-0.00.hdf5
11487/11487 [==============================] - 76s - loss: 0.0026 - acc: 0.9629
Epoch 36/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9628Epoch 00035: saving model to weights/weights.35-0.00.hdf5
11487/11487 [==============================] - 76s - loss: 0.0027 - acc: 0.9628
Epoch 37/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9630Epoch 00036: saving model to weights/weights.36-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0025 - acc: 0.9630
Epoch 38/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9630Epoch 00037: saving model to weights/weights.37-0.00.hdf5
11487/11487 [==============================] - 73s - loss: 0.0025 - acc: 0.9630
Epoch 39/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9630Epoch 00038: saving model to weights/weights.38-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0025 - acc: 0.9630
Epoch 40/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9630Epoch 00039: saving model to weights/weights.39-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0025 - acc: 0.9630
Epoch 41/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9630Epoch 00040: saving model to weights/weights.40-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0025 - acc: 0.9630
Epoch 42/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9631Epoch 00041: saving model to weights/weights.41-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0024 - acc: 0.9631
Epoch 43/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9630Epoch 00042: saving model to weights/weights.42-0.00.hdf5
11487/11487 [==============================] - 74s - loss: 0.0025 - acc: 0.9630
Epoch 44/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9630Epoch 00043: saving model to weights/weights.43-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0025 - acc: 0.9630
Epoch 45/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9631Epoch 00044: saving model to weights/weights.44-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0023 - acc: 0.9631
Epoch 46/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9632Epoch 00045: saving model to weights/weights.45-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0023 - acc: 0.9632
Epoch 47/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9632Epoch 00046: saving model to weights/weights.46-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0023 - acc: 0.9632
Epoch 48/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9631Epoch 00047: saving model to weights/weights.47-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0023 - acc: 0.9631
Epoch 49/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9632Epoch 00048: saving model to weights/weights.48-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0022 - acc: 0.9632
Epoch 50/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9632Epoch 00049: saving model to weights/weights.49-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0023 - acc: 0.9632
Epoch 51/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9631Epoch 00050: saving model to weights/weights.50-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0023 - acc: 0.9631
Epoch 52/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9632Epoch 00051: saving model to weights/weights.51-0.00.hdf5
11487/11487 [==============================] - 74s - loss: 0.0022 - acc: 0.9632
Epoch 53/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9633Epoch 00052: saving model to weights/weights.52-0.00.hdf5
11487/11487 [==============================] - 73s - loss: 0.0021 - acc: 0.9633
Epoch 54/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9632Epoch 00053: saving model to weights/weights.53-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0022 - acc: 0.9632
Epoch 55/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9631Epoch 00054: saving model to weights/weights.54-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0023 - acc: 0.9631
Epoch 56/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9633Epoch 00055: saving model to weights/weights.55-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0021 - acc: 0.9633
Epoch 57/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9633Epoch 00056: saving model to weights/weights.56-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0021 - acc: 0.9633
Epoch 58/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9633Epoch 00057: saving model to weights/weights.57-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0022 - acc: 0.9633
Epoch 59/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9633Epoch 00058: saving model to weights/weights.58-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0020 - acc: 0.9633
Epoch 60/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9633Epoch 00059: saving model to weights/weights.59-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0021 - acc: 0.9633
Epoch 61/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9633Epoch 00060: saving model to weights/weights.60-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0020 - acc: 0.9633
Epoch 62/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9632Epoch 00061: saving model to weights/weights.61-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0022 - acc: 0.9632
Epoch 63/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9634Epoch 00062: saving model to weights/weights.62-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0020 - acc: 0.9634
Epoch 64/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9634Epoch 00063: saving model to weights/weights.63-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0020 - acc: 0.9634
Epoch 65/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9633Epoch 00064: saving model to weights/weights.64-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0021 - acc: 0.9633
Epoch 66/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9634Epoch 00065: saving model to weights/weights.65-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0020 - acc: 0.9634
Epoch 67/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9634Epoch 00066: saving model to weights/weights.66-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0019 - acc: 0.9634
Epoch 68/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9634Epoch 00067: saving model to weights/weights.67-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0020 - acc: 0.9634
Epoch 69/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9634Epoch 00068: saving model to weights/weights.68-0.00.hdf5
11487/11487 [==============================] - 73s - loss: 0.0019 - acc: 0.9634
Epoch 70/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9634Epoch 00069: saving model to weights/weights.69-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0019 - acc: 0.9634
Epoch 71/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9634Epoch 00070: saving model to weights/weights.70-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0020 - acc: 0.9634
Epoch 72/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9634Epoch 00071: saving model to weights/weights.71-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0020 - acc: 0.9634
Epoch 73/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9635Epoch 00072: saving model to weights/weights.72-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0019 - acc: 0.9634
Epoch 74/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9634Epoch 00073: saving model to weights/weights.73-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0019 - acc: 0.9634
Epoch 75/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9634Epoch 00074: saving model to weights/weights.74-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0019 - acc: 0.9634
Epoch 76/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9634Epoch 00075: saving model to weights/weights.75-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0019 - acc: 0.9634
Epoch 77/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00076: saving model to weights/weights.76-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0018 - acc: 0.9635
Epoch 78/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9634Epoch 00077: saving model to weights/weights.77-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0019 - acc: 0.9634
Epoch 79/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00078: saving model to weights/weights.78-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0018 - acc: 0.9635
Epoch 80/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9634Epoch 00079: saving model to weights/weights.79-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0019 - acc: 0.9634
Epoch 81/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9635Epoch 00080: saving model to weights/weights.80-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0019 - acc: 0.9635
Epoch 82/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00081: saving model to weights/weights.81-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0018 - acc: 0.9635
Epoch 83/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9635Epoch 00082: saving model to weights/weights.82-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0019 - acc: 0.9635
Epoch 84/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9635Epoch 00083: saving model to weights/weights.83-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0019 - acc: 0.9635
Epoch 85/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00084: saving model to weights/weights.84-0.00.hdf5
11487/11487 [==============================] - 73s - loss: 0.0018 - acc: 0.9635
Epoch 86/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9634Epoch 00085: saving model to weights/weights.85-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0019 - acc: 0.9634
Epoch 87/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9636Epoch 00086: saving model to weights/weights.86-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0017 - acc: 0.9636
Epoch 88/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00087: saving model to weights/weights.87-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0018 - acc: 0.9635
Epoch 89/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00088: saving model to weights/weights.88-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0018 - acc: 0.9635
Epoch 90/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9636Epoch 00089: saving model to weights/weights.89-0.00.hdf5
11487/11487 [==============================] - 72s - loss: 0.0017 - acc: 0.9636
Epoch 91/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9636Epoch 00090: saving model to weights/weights.90-0.00.hdf5
11487/11487 [==============================] - 74s - loss: 0.0017 - acc: 0.9636
Epoch 92/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9636Epoch 00091: saving model to weights/weights.91-0.00.hdf5
11487/11487 [==============================] - 77s - loss: 0.0017 - acc: 0.9636
Epoch 93/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00092: saving model to weights/weights.92-0.00.hdf5
11487/11487 [==============================] - 77s - loss: 0.0018 - acc: 0.9635
Epoch 94/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00093: saving model to weights/weights.93-0.00.hdf5
11487/11487 [==============================] - 77s - loss: 0.0018 - acc: 0.9635
Epoch 95/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00094: saving model to weights/weights.94-0.00.hdf5
11487/11487 [==============================] - 76s - loss: 0.0018 - acc: 0.9635
Epoch 96/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9636Epoch 00095: saving model to weights/weights.95-0.00.hdf5
11487/11487 [==============================] - 77s - loss: 0.0017 - acc: 0.9636
Epoch 97/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9636Epoch 00096: saving model to weights/weights.96-0.00.hdf5
11487/11487 [==============================] - 77s - loss: 0.0017 - acc: 0.9636
Epoch 98/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00097: saving model to weights/weights.97-0.00.hdf5
11487/11487 [==============================] - 77s - loss: 0.0018 - acc: 0.9635
Epoch 99/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9635Epoch 00098: saving model to weights/weights.98-0.00.hdf5
11487/11487 [==============================] - 77s - loss: 0.0018 - acc: 0.9635
Epoch 100/100
11480/11487 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9636Epoch 00099: saving model to weights/weights.99-0.00.hdf5
11487/11487 [==============================] - 77s - loss: 0.0017 - acc: 0.9636
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_1 (InputLayer)             (None, 80, 160, 3)    0
____________________________________________________________________________________________________
batch_normalization_1 (BatchNorm (None, 80, 160, 3)    12          input_1[0][0]
____________________________________________________________________________________________________
Conv0 (Conv2D)                   (None, 78, 158, 8)    224         batch_normalization_1[0][0]
____________________________________________________________________________________________________
Conv1C (Conv2D)                  (None, 76, 156, 16)   1168        Conv0[0][0]
____________________________________________________________________________________________________
Pooling1C (MaxPooling2D)         (None, 38, 78, 16)    0           Conv1C[0][0]
____________________________________________________________________________________________________
Conv2C (Conv2D)                  (None, 36, 76, 32)    4640        Pooling1C[0][0]
____________________________________________________________________________________________________
Pooling2C (MaxPooling2D)         (None, 18, 38, 32)    0           Conv2C[0][0]
____________________________________________________________________________________________________
Conv1B (Conv2D)                  (None, 76, 156, 16)   1168        Conv0[0][0]
____________________________________________________________________________________________________
Conv3C (Conv2D)                  (None, 16, 36, 64)    18496       Pooling2C[0][0]
____________________________________________________________________________________________________
Pooling1B (MaxPooling2D)         (None, 38, 78, 16)    0           Conv1B[0][0]
____________________________________________________________________________________________________
Pooling3C (MaxPooling2D)         (None, 8, 18, 64)     0           Conv3C[0][0]
____________________________________________________________________________________________________
Conv2B (Conv2D)                  (None, 36, 76, 32)    4640        Pooling1B[0][0]
____________________________________________________________________________________________________
UpSampling1C (UpSampling2D)      (None, 16, 36, 64)    0           Pooling3C[0][0]
____________________________________________________________________________________________________
Pooling2B (MaxPooling2D)         (None, 18, 38, 32)    0           Conv2B[0][0]
____________________________________________________________________________________________________
Deconv1C (Conv2DTranspose)       (None, 18, 38, 64)    36928       UpSampling1C[0][0]
____________________________________________________________________________________________________
Conv1A (Conv2D)                  (None, 76, 156, 16)   1168        Conv0[0][0]
____________________________________________________________________________________________________
UpSampling1B (UpSampling2D)      (None, 36, 76, 32)    0           Pooling2B[0][0]
____________________________________________________________________________________________________
UpSampling2C (UpSampling2D)      (None, 36, 76, 64)    0           Deconv1C[0][0]
____________________________________________________________________________________________________
Pooling1A (MaxPooling2D)         (None, 38, 78, 16)    0           Conv1A[0][0]
____________________________________________________________________________________________________
Deconv1B (Conv2DTranspose)       (None, 38, 78, 32)    9248        UpSampling1B[0][0]
____________________________________________________________________________________________________
Deconv2C (Conv2DTranspose)       (None, 38, 78, 32)    18464       UpSampling2C[0][0]
____________________________________________________________________________________________________
UpSampling1A (UpSampling2D)      (None, 76, 156, 16)   0           Pooling1A[0][0]
____________________________________________________________________________________________________
UpSampling2B (UpSampling2D)      (None, 76, 156, 32)   0           Deconv1B[0][0]
____________________________________________________________________________________________________
UpSampling3C (UpSampling2D)      (None, 76, 156, 32)   0           Deconv2C[0][0]
____________________________________________________________________________________________________
Deconv1A (Conv2DTranspose)       (None, 78, 158, 16)   2320        UpSampling1A[0][0]
____________________________________________________________________________________________________
Deconv2B (Conv2DTranspose)       (None, 78, 158, 16)   4624        UpSampling2B[0][0]
____________________________________________________________________________________________________
Deconv3C (Conv2DTranspose)       (None, 78, 158, 16)   4624        UpSampling3C[0][0]
____________________________________________________________________________________________________
concatenate_1 (Concatenate)      (None, 78, 158, 48)   0           Deconv1A[0][0]
                                                                   Deconv2B[0][0]
                                                                   Deconv3C[0][0]
____________________________________________________________________________________________________
Deconv0 (Conv2DTranspose)        (None, 80, 160, 1)    433         concatenate_1[0][0]
====================================================================================================
Total params: 108,157
Trainable params: 108,151
Non-trainable params: 6
____________________________________________________________________________________________________